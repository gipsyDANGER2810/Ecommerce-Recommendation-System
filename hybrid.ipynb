{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:/Users/swapn/Desktop/testing/modified_dataset3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['discounted_price'] = df['discounted_price'].astype(str).str.replace('₹', '').str.replace(',', '').astype(float)\n",
    "df['actual_price'] = df['actual_price'].astype(str).str.replace('₹', '').str.replace(',', '').astype(float)\n",
    "df['discount_percentage'] = df['discount_percentage'].astype(str).str.replace('%','').astype(float)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de linhas com '|' na coluna 'rating': 8\n",
      "Total de linhas com '|' na coluna 'rating': 0\n"
     ]
    }
   ],
   "source": [
    "count = df['rating'].str.contains('\\|').sum()\n",
    "print(f\"Total de linhas com '|' na coluna 'rating': {count}\")\n",
    "df = df[df['rating'].apply(lambda x: '|' not in str(x))]\n",
    "count = df['rating'].str.contains('\\|').sum()\n",
    "print(f\"Total de linhas com '|' na coluna 'rating': {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           user_id  user_id_encoded\n",
      "0     AE22E2AXODSPNK3EBIHNGYS5LOSA                0\n",
      "1     AE22MK2NXQD3ZARLIOL3SLD4GU6A                1\n",
      "2     AE22Y3KIS7SE6LI3HE2VS6WWPU4Q                2\n",
      "3     AE23RS3W7GZO7LHYKJU6KSKVM4MQ                3\n",
      "4     AE23WGYTUMB5R6JJMBU4V43JIW7Q                4\n",
      "...                            ...              ...\n",
      "9037  AHZXNS63DN6MZDH3WSKYRLWSG3DA             9037\n",
      "9038  AHZYN7O73FJWRPUQGZM5BEAZ3A4A             9038\n",
      "9039  AHZZFBL24XXVLW6H44MOB6LBHH5A             9039\n",
      "9040  AHZZISWHBQV4TL3MKOJTH22IUNIQ             9040\n",
      "9041  AHZZXJWETMZR7SH7C22KVUT7VHAA             9041\n",
      "\n",
      "[9042 rows x 2 columns]\n",
      "                           user_id  user_id_encoded  count\n",
      "0     AE55KTFVNXYFD5FPYWP2OUPEYNPQ              226     11\n",
      "1     AG5DWPD54QGSLWJ6QUFERLPNAX4Q             4773     11\n",
      "2     AEAMIR3CMSA32IDEINSJKHRNANTA              451     10\n",
      "3     AEBWA5I4QFCA3P3OBEPMELBGN4GQ              536     10\n",
      "4     AECPFYFQVRUWC3KGNLJIOREFP5LQ              608     10\n",
      "...                            ...              ...    ...\n",
      "9037  AHZWXUWE3RGLDH4JJUK3HT3VMBJA             9035      1\n",
      "9038  AHZXNS63DN6MZDH3WSKYRLWSG3DA             9037      1\n",
      "9039  AHZYN7O73FJWRPUQGZM5BEAZ3A4A             9038      1\n",
      "9040  AHZZISWHBQV4TL3MKOJTH22IUNIQ             9040      1\n",
      "9041  AHZZXJWETMZR7SH7C22KVUT7VHAA             9041      1\n",
      "\n",
      "[9042 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df['rating'] = df['rating'].astype(str).str.replace(',', '').astype(float)\n",
    "df['rating_count'] = df['rating_count'].astype(str).str.replace(',', '').astype(float)\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['user_id_encoded'] = le.fit_transform(df['user_id'])\n",
    "\n",
    "encoded_df = df[['user_id', 'user_id_encoded']].drop_duplicates().sort_values(by='user_id_encoded').reset_index(drop=True)\n",
    "print(encoded_df)\n",
    "\n",
    "\n",
    "user_counts = df['user_id'].value_counts().reset_index()\n",
    "user_counts.columns = ['user_id', 'count']\n",
    "\n",
    "# Merge with the encoded_df\n",
    "encoded_df = encoded_df.merge(user_counts, on='user_id')\n",
    "\n",
    "# Sort by count and then by encoded value\n",
    "encoded_df = encoded_df.sort_values(by=['count', 'user_id_encoded'], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "print(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           product_name  rating  rating_count  \\\n",
      "9007  Swiffer Instant Electric Water Heater Faucet T...     4.8       53803.0   \n",
      "9006  Swiffer Instant Electric Water Heater Faucet T...     4.8       53803.0   \n",
      "9005  Swiffer Instant Electric Water Heater Faucet T...     4.8       53803.0   \n",
      "6793  SanDisk Extreme SD UHS I 64GB Card for 4K Vide...     4.5      205052.0   \n",
      "6789  SanDisk Extreme SD UHS I 64GB Card for 4K Vide...     4.5      205052.0   \n",
      "...                                                 ...     ...           ...   \n",
      "3239  PTron Tangent Lite Bluetooth 5.0 Earphones wit...     3.5       83996.0   \n",
      "3238  PTron Tangent Lite Bluetooth 5.0 Earphones wit...     3.5       83996.0   \n",
      "3237  PTron Tangent Lite Bluetooth 5.0 Earphones wit...     3.5       83996.0   \n",
      "3236  PTron Tangent Lite Bluetooth 5.0 Earphones wit...     3.5       83996.0   \n",
      "3234  PTron Tangent Lite Bluetooth 5.0 Earphones wit...     3.5       83996.0   \n",
      "\n",
      "      weighted_rating  \n",
      "9007         4.501759  \n",
      "9006         4.501759  \n",
      "9005         4.501759  \n",
      "6793         4.434731  \n",
      "6789         4.434731  \n",
      "...               ...  \n",
      "3239         3.691947  \n",
      "3238         3.691947  \n",
      "3237         3.691947  \n",
      "3236         3.691947  \n",
      "3234         3.691947  \n",
      "\n",
      "[1151 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\swapn\\AppData\\Local\\Temp\\ipykernel_24372\\811911763.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  qualified_products['weighted_rating'] = qualified_products.apply(weighted_rating, axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean rating across all products\n",
    "C = df['rating'].mean()\n",
    "\n",
    "# Calculate the 90th percentile of the number of ratings\n",
    "m = df['rating_count'].quantile(0.9)\n",
    "\n",
    "# Filter out movies that have a rating count less than m\n",
    "qualified_products = df[df['rating_count'] >= m]\n",
    "\n",
    "# Compute the weighted rating for each qualified product\n",
    "def weighted_rating(x, m=m, C=C):\n",
    "    v = x['rating_count']\n",
    "    R = x['rating']\n",
    "    return (v / (v + m) * R) + (m / (v + m) * C)\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "qualified_products['weighted_rating'] = qualified_products.apply(weighted_rating, axis=1)\n",
    "\n",
    "# Sort products based on score\n",
    "qualified_products = qualified_products.sort_values('weighted_rating', ascending=False)\n",
    "\n",
    "# Print the top recommendations\n",
    "print(qualified_products[['product_name', 'rating', 'rating_count', 'weighted_rating']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def content_based_filtering(df):\n",
    "    index_mapping = {index: i for i, index in enumerate(df.index)}\n",
    "\n",
    "    def create_tfidf_matrix(df_inner):\n",
    "        tfidf = TfidfVectorizer(stop_words='english')\n",
    "        df_inner['about_product'] = df_inner['about_product'].fillna('')\n",
    "        tfidf_matrix = tfidf.fit_transform(df_inner['about_product'])\n",
    "        return tfidf_matrix, tfidf\n",
    "\n",
    "    tfidf_matrix, tfidf = create_tfidf_matrix(df)\n",
    "\n",
    "    user_profiles = {}\n",
    "\n",
    "    for user_id_encoded in df['user_id_encoded'].unique():\n",
    "        user_data = df[df['user_id_encoded'] == user_id_encoded]\n",
    "        tfidf_indices = [index_mapping[idx] for idx in user_data.index.tolist()]\n",
    "        user_vector = np.sum(tfidf_matrix[tfidf_indices], axis=0)\n",
    "        user_vector = np.asarray(user_vector).reshape(1, -1)\n",
    "        user_vector_norm = user_vector / np.linalg.norm(user_vector)\n",
    "        user_profiles[user_id_encoded] = user_vector_norm\n",
    "\n",
    "    def recommend_products_with_profiles(user_id_encoded, tfidf_matrix):\n",
    "    # Fetch the user profile\n",
    "        user_vector = user_profiles.get(user_id_encoded, None)\n",
    "        \n",
    "        if user_vector is None:\n",
    "            return qualified_products[['product_name', 'rating', 'rating_count', 'weighted_rating']]  # Fallback to popular recommendations if no profile found\n",
    "        \n",
    "        # Calculate similarity between user profile and all products\n",
    "        cosine_sim_user = cosine_similarity(user_vector, tfidf_matrix)\n",
    "        cosine_sim_user = np.asarray(cosine_sim_user)\n",
    "\n",
    "        # Products the user has already interacted with\n",
    "        interacted_products = df.loc[df['user_id_encoded'] == user_id_encoded]['product_name'].tolist()\n",
    "        \n",
    "        similarity_scores = list(enumerate(cosine_sim_user[0]))\n",
    "        \n",
    "        # Filter out products the user has already interacted with\n",
    "        similarity_scores = [item for item in similarity_scores if df.iloc[item[0]]['product_name'] not in interacted_products]\n",
    "        similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        recommended_products_set = set()  # Use a set to keep track of unique recommended products\n",
    "        all_top_products = []\n",
    "        for idx, score in similarity_scores:\n",
    "            product_name = df.iloc[idx]['product_name']\n",
    "            if product_name not in recommended_products_set:\n",
    "                recommended_products_set.add(product_name)\n",
    "                all_top_products.append(idx)\n",
    "            if len(all_top_products) == 5:  # Stop once we have 5 unique recommendations\n",
    "                break\n",
    "\n",
    "        recommended_products_list = df.iloc[all_top_products]['product_name'].tolist()\n",
    "        valid_scores = [score for idx, score in similarity_scores if idx in all_top_products][:5]\n",
    "\n",
    "        results_df = pd.DataFrame({\n",
    "            'Id Encoded': [user_id_encoded] * len(recommended_products_list),\n",
    "            'recommended product': recommended_products_list,\n",
    "            'score recommendation': valid_scores\n",
    "        })\n",
    "\n",
    "        return results_df\n",
    "\n",
    "    return recommend_products_with_profiles, tfidf_matrix\n",
    "\n",
    "# recommender_function, tfidf_matrix_out = content_based_filtering(df)\n",
    "# recommendations = recommender_function(4223423424, tfidf_matrix_out)\n",
    "# print(recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           product_name  rating  rating_count  \\\n",
      "9007  Swiffer Instant Electric Water Heater Faucet T...     4.8       53803.0   \n",
      "9006  Swiffer Instant Electric Water Heater Faucet T...     4.8       53803.0   \n",
      "9005  Swiffer Instant Electric Water Heater Faucet T...     4.8       53803.0   \n",
      "6793  SanDisk Extreme SD UHS I 64GB Card for 4K Vide...     4.5      205052.0   \n",
      "6789  SanDisk Extreme SD UHS I 64GB Card for 4K Vide...     4.5      205052.0   \n",
      "...                                                 ...     ...           ...   \n",
      "3239  PTron Tangent Lite Bluetooth 5.0 Earphones wit...     3.5       83996.0   \n",
      "3238  PTron Tangent Lite Bluetooth 5.0 Earphones wit...     3.5       83996.0   \n",
      "3237  PTron Tangent Lite Bluetooth 5.0 Earphones wit...     3.5       83996.0   \n",
      "3236  PTron Tangent Lite Bluetooth 5.0 Earphones wit...     3.5       83996.0   \n",
      "3234  PTron Tangent Lite Bluetooth 5.0 Earphones wit...     3.5       83996.0   \n",
      "\n",
      "      weighted_rating  \n",
      "9007         4.501759  \n",
      "9006         4.501759  \n",
      "9005         4.501759  \n",
      "6793         4.434731  \n",
      "6789         4.434731  \n",
      "...               ...  \n",
      "3239         3.691947  \n",
      "3238         3.691947  \n",
      "3237         3.691947  \n",
      "3236         3.691947  \n",
      "3234         3.691947  \n",
      "\n",
      "[1151 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "recommender_function, tfidf_matrix_out = content_based_filtering(df)\n",
    "recommendations = recommender_function(4223423424, tfidf_matrix_out)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prerequisites_collaborative():\n",
    "    x = df.groupby('user_id_encoded').count()['rating'] > 3\n",
    "    users_rated = x[x].index\n",
    "    filtered_df = df[df['user_id_encoded'].isin(users_rated)]\n",
    "    y = filtered_df.groupby('product_name').count()['rating'] > 1\n",
    "    high_rated_products = y[y].index\n",
    "    final_rating = filtered_df[filtered_df['product_name'].isin(high_rated_products)]\n",
    "    \n",
    "    # Create a user-item matrix\n",
    "    pt = final_rating.pivot_table(index='user_id_encoded', columns='product_name', values='rating')\n",
    "    pt.fillna(0, inplace=True)\n",
    "    return pt\n",
    "\n",
    "pt = prerequisites_collaborative()\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_score = cosine_similarity(pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(user_id_encoded):\n",
    "    \"\"\"Return a list of recommended products for a given user.\"\"\"\n",
    "    try:\n",
    "        index = np.where(pt.index == user_id_encoded)[0][0]\n",
    "        print(f\"Index for user_id_encoded: {user_id_encoded}: {index}\")\n",
    "        \n",
    "        # Find similar users\n",
    "        similar_users = sorted(list(enumerate(similarity_score[index])), key=lambda x: x[1], reverse=True)[1:6]\n",
    "        print(f\"Similar users: {similar_users}\")\n",
    "        \n",
    "        # Get the items that these users have interacted with\n",
    "        recommended_products = []\n",
    "        for i in similar_users:\n",
    "            user_id = pt.index[i[0]]\n",
    "            rated_products = pt.columns[(pt.loc[user_id] > 0)].tolist()\n",
    "            recommended_products.extend(rated_products)\n",
    "        \n",
    "        # Remove duplicates and return\n",
    "        recommended_products = list(set(recommended_products))\n",
    "        print(f\"Recommended products: {recommended_products}\")\n",
    "    except IndexError:\n",
    "        print(f\"Error: user_id_encoded {user_id_encoded} not found in index.\")\n",
    "        recommended_products = qualified_products[['product_name', 'rating', 'rating_count', 'weighted_rating']]\n",
    "\n",
    "    return recommended_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_recommendation(user_id_encoded, alpha=0.6):\n",
    "    \"\"\"\n",
    "    alpha: Determines the weightage to be given to content-based vs collaborative filtering.\n",
    "    An alpha of 0.5 means both will have equal weightage.\n",
    "    \"\"\"\n",
    "    # 1. Get recommendations from Content-based Recommendation System\n",
    "    recommender_function, tfidf_matrix_out = content_based_filtering(df)\n",
    "    content_based_recommendations = recommender_function(user_id_encoded, tfidf_matrix_out)\n",
    "    \n",
    "    # 2. Get recommendations from Collaborative Filtering System (user-based CF)\n",
    "    collaborative_recommendations = get_recommendations(user_id_encoded)[:6]\n",
    "    \n",
    "    # 3. Combine the scores (if possible, else can just concatenate lists and de-duplicate)\n",
    "    \n",
    "    # Let's say the content-based system gave scores in the 'score recommendation' column.\n",
    "    # Multiply the scores with alpha for content-based recommendations\n",
    "    content_based_recommendations['score recommendation'] *= alpha\n",
    "    \n",
    "    # For the collaborative filtering system, we can assign scores based on ranks.\n",
    "    collaborative_scores = [(1 - idx * 0.1) * (1 - alpha) for idx in range(len(collaborative_recommendations))]\n",
    "    \n",
    "    # Concatenate the lists and scores\n",
    "    combined_products = content_based_recommendations['recommended product'].tolist() + collaborative_recommendations\n",
    "    combined_scores = content_based_recommendations['score recommendation'].tolist() + collaborative_scores\n",
    "    \n",
    "    # Deduplicate\n",
    "    seen = set()\n",
    "    final_recommendations = []\n",
    "    final_scores = []\n",
    "    for prod, score in zip(combined_products, combined_scores):\n",
    "        if prod not in seen:\n",
    "            final_recommendations.append(prod)\n",
    "            final_scores.append(score)\n",
    "            seen.add(prod)\n",
    "    \n",
    "    return pd.DataFrame({'Product': final_recommendations, 'Score': final_scores})\n",
    "\n",
    "# Use\n",
    "# recommendations = hybrid_recommendation()\n",
    "# print(recommendations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actual_ratings(user_id, df):\n",
    "    \"\"\"\n",
    "    Fetches the actual ratings given by a user.\n",
    "\n",
    "    Parameters:\n",
    "    - user_id: The encoded user ID for which you want to fetch actual ratings.\n",
    "    - df: The DataFrame containing the user ratings data.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary where keys are product names and values are the corresponding ratings.\n",
    "    \"\"\"\n",
    "    # Filter the dataframe to get rows where user ID matches\n",
    "    user_ratings = df[df['user_id_encoded'] == user_id]\n",
    "    \n",
    "    # Convert the product names and ratings to dictionary\n",
    "    ratings_dict = dict(zip(user_ratings['product_name'], user_ratings['rating']))\n",
    "\n",
    "    return ratings_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: user_id_encoded 1048 not found in index.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to coerce to Series, length must be 4: given 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\swapn\\Desktop\\Ecomm Recommendation System\\hybrid.ipynb Cell 14\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/swapn/Desktop/Ecomm%20Recommendation%20System/hybrid.ipynb#X16sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m user_id \u001b[39m=\u001b[39m \u001b[39m1048\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/swapn/Desktop/Ecomm%20Recommendation%20System/hybrid.ipynb#X16sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# Fetch recommended products for the user\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/swapn/Desktop/Ecomm%20Recommendation%20System/hybrid.ipynb#X16sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m recommendations_df \u001b[39m=\u001b[39m hybrid_recommendation(user_id)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/swapn/Desktop/Ecomm%20Recommendation%20System/hybrid.ipynb#X16sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# Fetch actual ratings for the user\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/swapn/Desktop/Ecomm%20Recommendation%20System/hybrid.ipynb#X16sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m actual_ratings_dict \u001b[39m=\u001b[39m get_actual_ratings(user_id, df)\n",
      "\u001b[1;32mc:\\Users\\swapn\\Desktop\\Ecomm Recommendation System\\hybrid.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/swapn/Desktop/Ecomm%20Recommendation%20System/hybrid.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m collaborative_scores \u001b[39m=\u001b[39m [(\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m idx \u001b[39m*\u001b[39m \u001b[39m0.1\u001b[39m) \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m alpha) \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(collaborative_recommendations))]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/swapn/Desktop/Ecomm%20Recommendation%20System/hybrid.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Concatenate the lists and scores\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/swapn/Desktop/Ecomm%20Recommendation%20System/hybrid.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m combined_products \u001b[39m=\u001b[39m content_based_recommendations[\u001b[39m'\u001b[39;49m\u001b[39mrecommended product\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mtolist() \u001b[39m+\u001b[39;49m collaborative_recommendations\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/swapn/Desktop/Ecomm%20Recommendation%20System/hybrid.ipynb#X16sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m combined_scores \u001b[39m=\u001b[39m content_based_recommendations[\u001b[39m'\u001b[39m\u001b[39mscore recommendation\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtolist() \u001b[39m+\u001b[39m collaborative_scores\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/swapn/Desktop/Ecomm%20Recommendation%20System/hybrid.ipynb#X16sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Deduplicate\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\ops\\common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m     79\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 81\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\arraylike.py:190\u001b[0m, in \u001b[0;36mOpsMixin.__radd__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__radd__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__radd__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m--> 190\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_arith_method(other, roperator\u001b[39m.\u001b[39;49mradd)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:7455\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   7452\u001b[0m axis: Literal[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m  \u001b[39m# only relevant for Series other case\u001b[39;00m\n\u001b[0;32m   7453\u001b[0m other \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mmaybe_prepare_scalar_for_op(other, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[axis],))\n\u001b[1;32m-> 7455\u001b[0m \u001b[39mself\u001b[39m, other \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49malign_method_FRAME(\u001b[39mself\u001b[39;49m, other, axis, flex\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, level\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   7457\u001b[0m new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dispatch_frame_op(other, op, axis\u001b[39m=\u001b[39maxis)\n\u001b[0;32m   7458\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(new_data)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\ops\\__init__.py:306\u001b[0m, in \u001b[0;36malign_method_FRAME\u001b[1;34m(left, right, axis, flex, level)\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    303\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnable to coerce list of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(right[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m to Series/DataFrame\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    304\u001b[0m         )\n\u001b[0;32m    305\u001b[0m     \u001b[39m# GH17901\u001b[39;00m\n\u001b[1;32m--> 306\u001b[0m     right \u001b[39m=\u001b[39m to_series(right)\n\u001b[0;32m    308\u001b[0m \u001b[39mif\u001b[39;00m flex \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(right, ABCDataFrame):\n\u001b[0;32m    309\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m left\u001b[39m.\u001b[39m_indexed_same(right):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\ops\\__init__.py:252\u001b[0m, in \u001b[0;36malign_method_FRAME.<locals>.to_series\u001b[1;34m(right)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    251\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(left\u001b[39m.\u001b[39mcolumns) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(right):\n\u001b[1;32m--> 252\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    253\u001b[0m             msg\u001b[39m.\u001b[39mformat(req_len\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(left\u001b[39m.\u001b[39mcolumns), given_len\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(right))\n\u001b[0;32m    254\u001b[0m         )\n\u001b[0;32m    255\u001b[0m     right \u001b[39m=\u001b[39m left\u001b[39m.\u001b[39m_constructor_sliced(right, index\u001b[39m=\u001b[39mleft\u001b[39m.\u001b[39mcolumns, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    256\u001b[0m \u001b[39mreturn\u001b[39;00m right\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to coerce to Series, length must be 4: given 5"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "def compute_rmse(actual_ratings, predicted_scores):\n",
    "    # Ensure both lists are of the same length\n",
    "    if len(actual_ratings) != len(predicted_scores):\n",
    "        raise ValueError(\"The lists of actual ratings and predicted scores must have the same length\")\n",
    "    \n",
    "    rmse = sqrt(mean_squared_error(actual_ratings, predicted_scores))\n",
    "    return rmse\n",
    "\n",
    "\n",
    "def get_actual_ratings(user_id, df):\n",
    "    \"\"\"\n",
    "    Fetches the actual ratings given by a user.\n",
    "\n",
    "    Parameters:\n",
    "    - user_id: The encoded user ID for which you want to fetch actual ratings.\n",
    "    - df: The DataFrame containing the user ratings data.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary where keys are product names and values are the corresponding ratings.\n",
    "    \"\"\"\n",
    "    # Filter the dataframe to get rows where user ID matches\n",
    "    user_ratings = df[df['user_id_encoded'] == user_id]\n",
    "    \n",
    "    # Convert the product names and ratings to dictionary\n",
    "    ratings_dict = dict(zip(user_ratings['product_name'], user_ratings['rating']))\n",
    "\n",
    "    return ratings_dict\n",
    "\n",
    "#  451     10\n",
    "# 3     AEBWA5I4QFCA3P3OBEPMELBGN4GQ              536     10\n",
    "# 4     AECPFYFQVRUWC3KGNLJIOREFP5LQ              608 \n",
    "# For demonstration:\n",
    "user_id = 1048\n",
    "\n",
    "# Fetch recommended products for the user\n",
    "recommendations_df = hybrid_recommendation(user_id)\n",
    "\n",
    "# Fetch actual ratings for the user\n",
    "actual_ratings_dict = get_actual_ratings(user_id, df)\n",
    "\n",
    "# Extract actual ratings for the recommended products\n",
    "actual_ratings = [actual_ratings_dict.get(prod, 0) for prod in recommendations_df['Product'].tolist()]\n",
    "\n",
    "# Now you can use the compute_rmse function as shown before\n",
    "predicted_scores = recommendations_df['Score'].tolist()\n",
    "rmse = compute_rmse(actual_ratings, predicted_scores)\n",
    "print(f\"RMSE for user {user_id}: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_over_users(user_ids, df):\n",
    "#     rmses = []\n",
    "#     for user_id in user_ids:\n",
    "#         recommendations_df = hybrid_recommendation(user_id)\n",
    "#         actual_ratings_dict = get_actual_ratings(user_id, df)\n",
    "\n",
    "#         common_products = set(recommendations_df['Product']) & set(actual_ratings_dict.keys())\n",
    "#         filtered_recommendations_df = recommendations_df[recommendations_df['Product'].isin(common_products)]\n",
    "\n",
    "#         if len(filtered_recommendations_df) == 0:\n",
    "#             continue  # skip this user if no common products\n",
    "\n",
    "#         actual_ratings = [actual_ratings_dict[prod] for prod in filtered_recommendations_df['Product'].tolist()]\n",
    "#         predicted_scores = filtered_recommendations_df['Score'].tolist()\n",
    "        \n",
    "#         rmse = compute_rmse(actual_ratings, predicted_scores)\n",
    "#         rmses.append(rmse)\n",
    "    \n",
    "#     return np.mean(rmses)  # Return the average RMSE over all users\n",
    "\n",
    "# # Use the function\n",
    "# user_ids_sample = [1048, 1050, 1065]  # You can choose a representative sample of user_ids\n",
    "# average_rmse = evaluate_over_users(user_ids_sample, df)\n",
    "# print(f\"RMSE: {average_rmse}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index for user_id_encoded: 1048: 716\n",
      "Similar users: [(337, 0.24753688574416852), (548, 0.20907512365103711), (810, 0.19754591932991789), (397, 0.19214858184417052), (21, 0.17960530202677488)]\n",
      "Recommended products: ['KONVIO NEER 10 Inch Spun Filter (PP SPUN) Cartridge Compatible for 10 Inch Pre-Filter Housing of Water Purifier | Pack of 4 Spun', 'Faber-Castell Connector Pen Set - Pack of 25 (Assorted)', 'boAt Wave Call Smart Watch, Smart Talk with Advanced Dedicated Bluetooth Calling Chip, 1.69” HD Display with 550 NITS & 70% Color Gamut, 150+ Watch Faces, Multi-Sport Modes, HR, SpO2, IP68(Deep Blue)', 'Myvn 30W Warp/20W Dash Charging Usb Type C Charger Cable Compatible For Cellular Phones Oneplus 8T 8 8Pro 7 Pro / 7T / 7T Pro Nord And Oneplus 3 / 3T / 5 / 5T / 6 / 6T / 7', 'Bajaj Frore 1200 mm Ceiling Fan (Brown)', 'Usha CookJoy (CJ1600WPC) 1600 Watt Induction cooktop (Black)', 'Acer 80 cm (32 inches) I Series HD Ready Android Smart LED TV AR32AR2841HDFL (Black)', 'OpenTech® Military-Grade Tempered Glass Screen Protector Compatible for iPhone 13/13 Pro / 14 with Edge to Edge Coverage and Easy Installation kit (6.1 Inches)', 'Offbeat® - DASH 2.4GHz Wireless + Bluetooth 5.1 Mouse, Multi-Device Dual Mode Slim Rechargeable Silent Click Buttons Wireless Bluetooth Mouse, 3 Adjustable DPI, Works on 2 devices at the same time with a switch button for Windows/Mac/Android/Ipad/Smart TV', 'boAt Newly Launched Wave Electra with 1.81\" HD Display, Smart Calling with Ultra-Seamless BT Calling Chip,20 Built-In Watch Faces,100 + Sports Modes,Menu Personalization,In-Built Games(Charcoal Black)', 'Sure From Aquaguard Delight NXT RO+UV+UF+Taste Adjuster(MTDS),6L water purifier,8 stages purification,Suitable for borewell,tanker,municipal water(Black) from Eureka Forbes', 'Flix (Beetel) Usb To Type C Pvc Data Sync And 2A 480Mbps Data Sync, Tough Fast Charging Long Cable For Usb Type C Devices, Charging Adapter (White, 1 Meter) - Xcd-C12', 'ZEBRONICS Zeb-Astra 20 Wireless BT v5.0 Portable Speaker with 10W RMS Output, TWS, 10H Backup Approx, Built in Rechargeable Battery FM Radio, AUX, mSD, USB, Call Function and Dual 52mm Drivers Multi', 'Skadioo WiFi Adapter for pc | Car Accessories, WiFi Dongle for pc | USB WiFi Adapter for pc | Wi-Fi Receiver 2.4GHz, 802.11b/g/n UNano Size WiFi Dongle Compatible Adapter,WiFi dongle for pc', 'Aqua d pure Active Copper 12-L RO+UV Water Filter Purifier for Home, Kitchen Fully Automatic UF+TDS Controller', 'FLiX (Beetel Flow USB to Micro USB PVC Data Sync & 12W(2.4A) Fast Charging Cable,Made in India,480Mbps Data Sync,Solid Cable,1 Meter Long cable for all Andriod & Micro USB Devices (Black)(XCD-FPM01)', 'TVARA LCD Writing Tablet 8.5 Inch E-Note Pad LCD Writing Tablet, Kids Drawing Pad 8.5 Inch Doodle Board, Toddler Boy and Girl Learning Gift for 3 4 5 6 Years Old, Black', 'Redmi 9A Sport (Coral Green, 3GB RAM, 32GB Storage) | 2GHz Octa-core Helio G25 Processor | 5000 mAh Battery', 'Astigo Compatible Remote for Airtel Digital Set Top Box (Pairing Required with TV Remote)', 'Havells Instanio 1-Litre 3KW Instant Water Heater (Geyser), White Blue', 'FLiX (Beetel USB to Micro USB PVC Data Sync & 2A Fast Charging Cable, Made in India, 480Mbps Data Sync, Solid Cable, 1 Meter Long USB Cable for Micro USB Devices (White)(XCD-M11)', 'Simxen Egg Boiler Electric Automatic Off 7 Egg Poacher for Steaming, Cooking Also Boiling and Frying 400 W (Blue, Pink)', 'GIZGA Club-laptop Neoprene Reversible for 15.6-inches Laptop Sleeve - Black-Red', 'FLiX (Beetel) 3in1 (Type C|Micro|Iphone Lightening) Textured Pattern 3A Fast Charging Cable with QC & PD Support for Type C,Micro USB & Lightning Iphone Cable,Made in India,1.5 Meter Long Cable(T101)']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\swapn\\Desktop\\Ecomm Recommendation System\\hybrid.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/swapn/Desktop/Ecomm%20Recommendation%20System/hybrid.ipynb#X21sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(actual_ratings) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(predicted_scores), \u001b[39m\"\u001b[39m\u001b[39mLength mismatch between actual and predicted ratings!\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/swapn/Desktop/Ecomm%20Recommendation%20System/hybrid.ipynb#X21sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Now you can use the compute_rmse function\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/swapn/Desktop/Ecomm%20Recommendation%20System/hybrid.ipynb#X21sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m rmse \u001b[39m=\u001b[39m compute_rmse(actual_ratings, predicted_scores)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/swapn/Desktop/Ecomm%20Recommendation%20System/hybrid.ipynb#X21sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRMSE for user \u001b[39m\u001b[39m{\u001b[39;00muser_id\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mrmse\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\swapn\\Desktop\\Ecomm Recommendation System\\hybrid.ipynb Cell 16\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/swapn/Desktop/Ecomm%20Recommendation%20System/hybrid.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(actual_ratings) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(predicted_scores):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/swapn/Desktop/Ecomm%20Recommendation%20System/hybrid.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe lists of actual ratings and predicted scores must have the same length\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/swapn/Desktop/Ecomm%20Recommendation%20System/hybrid.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m rmse \u001b[39m=\u001b[39m sqrt(mean_squared_error(actual_ratings, predicted_scores))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/swapn/Desktop/Ecomm%20Recommendation%20System/hybrid.ipynb#X21sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m rmse\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:474\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m    405\u001b[0m     {\n\u001b[0;32m    406\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    415\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, multioutput\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muniform_average\u001b[39m\u001b[39m\"\u001b[39m, squared\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    416\u001b[0m ):\n\u001b[0;32m    417\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \n\u001b[0;32m    419\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[39m    0.825...\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 474\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    475\u001b[0m         y_true, y_pred, multioutput\n\u001b[0;32m    476\u001b[0m     )\n\u001b[0;32m    477\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    478\u001b[0m     output_errors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maverage((y_true \u001b[39m-\u001b[39m y_pred) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, weights\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:100\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[39m    correct keyword.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     99\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m--> 100\u001b[0m y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    101\u001b[0m y_pred \u001b[39m=\u001b[39m check_array(y_pred, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    103\u001b[0m \u001b[39mif\u001b[39;00m y_true\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:969\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n\u001b[0;32m    968\u001b[0m     \u001b[39mif\u001b[39;00m n_samples \u001b[39m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 969\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    970\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m sample(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    971\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    972\u001b[0m             \u001b[39m%\u001b[39m (n_samples, array\u001b[39m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    973\u001b[0m         )\n\u001b[0;32m    975\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_features \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    976\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "user_id = 1048\n",
    "\n",
    "# Assuming a function `get_actual_ratings` returns the actual ratings for a user for the items in your recommendation list\n",
    "actual_ratings = get_actual_ratings(user_id,df)\n",
    "\n",
    "# Fetch recommended products for the user\n",
    "recommendations_df = hybrid_recommendation(user_id)\n",
    "\n",
    "# Fetch actual ratings for the user\n",
    "actual_ratings_dict = get_actual_ratings(user_id, df)\n",
    "\n",
    "# Filter the recommendations to include only products that are also present in the actual ratings\n",
    "common_products = set(recommendations_df['Product']) & set(actual_ratings_dict.keys())\n",
    "\n",
    "filtered_recommendations_df = recommendations_df[recommendations_df['Product'].isin(common_products)]\n",
    "\n",
    "# Extract ratings for the common products\n",
    "actual_ratings = [actual_ratings_dict[prod] for prod in filtered_recommendations_df['Product'].tolist()]\n",
    "predicted_scores = filtered_recommendations_df['Score'].tolist()\n",
    "\n",
    "# Ensure lengths match\n",
    "assert len(actual_ratings) == len(predicted_scores), \"Length mismatch between actual and predicted ratings!\"\n",
    "\n",
    "# Now you can use the compute_rmse function\n",
    "rmse = compute_rmse(actual_ratings, predicted_scores)\n",
    "print(f\"RMSE for user {user_id}: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
